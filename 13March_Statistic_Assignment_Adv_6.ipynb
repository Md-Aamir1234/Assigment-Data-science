{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
        "the validity of the results."
      ],
      "metadata": {
        "id": "Eh1NJBmYqECd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans1.\n",
        "\n",
        "# ANOVA (Analysis of Variance) is a statistical method used to compare means among three or more groups to determine\n",
        "→ if at least one group mean is significantly different from the others. To validly use ANOVA, several key assumptions must be met:\n",
        "\n",
        "# Assumptions of ANOVA :\n",
        "\n",
        "# 1.Independence of Observations:\n",
        "\n",
        "# Each sample or group must be composed of independent observations.\n",
        "→  Example Violation: If the data points within a group are correlated (e.g., repeated measures on the same subjects), the independence assumption is violated.\n",
        "\n",
        "# 2.Normality:\n",
        "\n",
        "# The data within each group should be approximately normally distributed.\n",
        "→  Example Violation: If the data are heavily skewed or have outliers, this assumption is violated. This can be checked using normality tests like the Shapiro-Wilk test or by visualizing data with Q-Q plots.\n",
        "\n",
        "# 3.Homogeneity of Variances (Homoscedasticity):\n",
        "\n",
        "→ The variances among the groups should be approximately equal.\n",
        "→  Example Violation: If one group has a much larger variance than the others, this assumption is violated. Levene's test or Bartlett's test can be used to assess this.\n",
        "\n",
        "# Examples of Violations and Their Impact\n",
        "\n",
        "# 1.Independence Violation:\n",
        "\n",
        "→ If observations are not independent, for instance, if measurements are taken from the same subjects multiple times without accounting for the repeated measures,\n",
        "→  it could lead to underestimating the variability within groups.This underestimation can result in a higher Type I error rate (incorrectly rejecting the null hypothesis).\n",
        "\n",
        "# 2.Normality Violation:\n",
        "\n",
        "→  If the data are not normally distributed, especially with small sample sizes, the ANOVA results might not be reliable.\n",
        "→  Non-normal data can lead to incorrect conclusions because the F-statistic may not follow the expected distribution, increasing the chances of both Type I and Type II errors.\n",
        "→  Example: In a study comparing blood pressure levels across different age groups, if one group's data are highly skewed due to an outlier, the normality assumption is violated.\n",
        "\n",
        "# 3.Homogeneity of Variances Violation:\n",
        "\n",
        "→  Unequal variances can affect the F-statistic, making it more difficult to determine if observed differences are significant. This can lead to inaccurate p-values, impacting the validity of the results.\n",
        "→ Example: In a test comparing the effectiveness of different diets on weight loss, if one diet group has a much higher variance in weight loss due to varied adherence to the diet, the homogeneity assumption is violated.\n",
        "\n",
        "# Addressing Violations  :\n",
        "→ Transformations: Applying a transformation to the data (e.g., log transformation) can help meet the normality and homogeneity of variances assumptions.\n",
        "→ Alternative Tests: Using non-parametric tests like the Kruskal-Wallis test, which do not require the normality assumption, can be a solution when normality is violated.\n",
        "→ Mixed-Effects Models: When independence is violated due to repeated measures or hierarchical data structures, mixed-effects models or repeated measures ANOVA can be used to appropriately account for the dependency.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wl8VpNl_rc_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What are the three types of ANOVA, and in what situations would each be used?"
      ],
      "metadata": {
        "id": "bfnVpYlCqEAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans2.\n",
        "\n",
        "# ANOVA (Analysis of Variance) can be categorized into three main types: One-Way ANOVA, Two-Way ANOVA, and Repeated Measures ANOVA. Each type is used in different situations based on the study design and the number of factors being analyzed.\n",
        "\n",
        "# 1. One-Way ANOVA\n",
        "\n",
        "→ Description: One-Way ANOVA is used to compare the means of three or more independent (unrelated) groups based on one independent variable (factor).\n",
        "\n",
        "→  Use Case: When you have one categorical independent variable with more than two levels (groups) and one continuous dependent variable.\n",
        "\n",
        "→  Example: A researcher wants to compare the average test scores of students from three different teaching methods (traditional, online, and hybrid).\n",
        "→  The independent variable is the teaching method (with three levels), and the dependent variable is the test scores.\n",
        "\n",
        "# 2. Two-Way ANOVA\n",
        "\n",
        "→  Description: Two-Way ANOVA is used to compare the means among groups that are split on two independent variables (factors).\n",
        "→  It can also evaluate the interaction effect between the two factors.\n",
        "\n",
        "→  Use Case: When you have two categorical independent variables and one continuous dependent variable.\n",
        "→  This type of ANOVA helps in understanding both the main effects of each factor and the interaction effect between them.\n",
        "\n",
        "→  Example: A researcher wants to study the effects of diet type (vegetarian, non-vegetarian) and exercise frequency (none, moderate, high) on weight loss.\n",
        "→  The independent variables are diet type and exercise frequency, and the dependent variable is weight loss.\n",
        "\n",
        "# 3. Repeated Measures ANOVA\n",
        "\n",
        "→ Description: Repeated Measures ANOVA is used when the same subjects are measured multiple times under different conditions or at different time points.\n",
        "→  This type accounts for the correlation between the repeated measures on the same subjects.\n",
        "\n",
        "→  Use Case: When you have one categorical independent variable with more than two levels, but the same subjects are used in each level.\n",
        "→  This is common in longitudinal studies or crossover designs.\n",
        "\n",
        "→  Example: A researcher wants to compare the effect of a drug on blood pressure measured at three different time points (baseline, 1 month, 3 months) in the same group of patients.\n",
        "→  The independent variable is the time point, and the dependent variable is blood pressure.\n",
        "\n",
        "\n",
        "# Summary :\n",
        "\n",
        "→ One-Way ANOVA: Used for comparing means across multiple independent groups based on one factor.\n",
        "→ Example: Comparing test scores of students from three different teaching methods.\n",
        "→  Two-Way ANOVA: Used for comparing means across groups based on two factors and understanding their interaction.\n",
        "→  Example: Studying the effect of diet type and exercise frequency on weight loss.\n",
        "→  Repeated Measures ANOVA: Used for comparing means when the same subjects are measured multiple times under different conditions.\n",
        "→  Example: Measuring the effect of a drug on blood pressure at different time points in the same patients.\n",
        "\n"
      ],
      "metadata": {
        "id": "cHv1DiTSrdiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
      ],
      "metadata": {
        "id": "zi6YSGvmqD9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans3.\n",
        "\n",
        "# Partitioning of variance in ANOVA is a fundamental concept that involves dividing the total variability in the data into components associated with different sources.\n",
        "#  This helps in understanding how much of the total variability is explained by the factors being studied and how much is due to random error. Understanding this concept is crucial for interpreting the results of an ANOVA test.\n",
        "\n",
        "# Partitioning of Variance :\n",
        "\n",
        "# 1.Total Sum of Squares (SST):\n",
        "\n",
        "→ Represents the total variability in the data.\n",
        "→  Calculated as the sum of the squared differences between each observation and the overall mean.\n",
        "\n",
        "Formula :\n",
        "\n",
        "→  SST = ∑(x - x̄ )^2\n",
        "\n",
        "# 2.Between-Group Sum of Squares (SSB):\n",
        "\n",
        "→  Represents the variability between the group means.\n",
        "→  Calculated as the sum of the squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
        "\n",
        "Formula :\n",
        "\n",
        "→  SST = ∑n(X_i - x̄ )^2\n",
        "\n",
        "Where :\n",
        "→ n is the number of observation in group i,\n",
        "→ X_i is the mean of group i,\n",
        "→ x̄ is the overall mean\n",
        "\n",
        "# 3.Within-Group Sum of Squares (SSW):\n",
        "\n",
        "→  Represents the variability within each group.\n",
        "→  Calculated as the sum of the squared differences between each observation and its respective group mean.\n",
        "\n",
        "Formula :\n",
        "\n",
        "→  SSW = ∑∑n(X_ij - x̄ )^2\n",
        "\n",
        "##  Importance of Partitioning Variance\n",
        "\n",
        "# 1.Understanding Sources of Variability:\n",
        "\n",
        "→ Partitioning variance helps identify the contributions of different sources (between groups and within groups) to the total variability.\n",
        "→  This provides insights into the factors influencing the dependent variable.\n",
        "\n",
        "# 2.Calculating the F-Statistic:\n",
        "\n",
        "→  The F-statistic is used to determine if the observed variability between groups is significantly greater than the variability within groups.\n",
        "\n",
        "# Formula for F-statistic :\n",
        "\n",
        "→  F = MSB / MSW\n",
        "\n",
        "→  Where MSB (Mean square between) is SSB/df_B , and MSW (Mean square within) is SSW/df_W.\n",
        "\n",
        "# Degree of freedom : df_B = k - 1 (k is the number of groups) and df_W = N-k (N is the total number of observations).\n",
        "\n",
        "# 3. Hypothesis Testing :\n",
        "\n",
        "→ By partitioning the variance, we can perform hypothesis testing to determine if there are significance differences between group means.\n",
        "→  Null hypothesis (Ho) : All group means are equal.\n",
        "→ Alternative hypothesis (Ha) : At least one group mean is different.\n",
        "→  The F-statistic and the corresponding p-value are used to reject the null hypothesis.\n",
        "\n",
        "# 4.Effect Size Calcultation :\n",
        "→ Partitioning variance allows for the calculation of effect size measures, such as Eta-square(n^2) , which indicate the proportion of total variance explained by the independent variable.\n",
        "\n",
        "→ Formula : for Eta-square :(n^2) = SSB/SST\n",
        "\n",
        "# Example :\n",
        "→  Consider a study comparing the test scores of students taught using three different methods (A, B, and C). The steps involved in partitioning variance would be:\n",
        "\n",
        "→ Calculate the overall mean test score.\n",
        "→ Calculate the mean test score for each teaching method.\n",
        "→ Compute the SST, SSB, and SSW using the formulas above.\n",
        "→ Calculate the F-statistic and compare it to a critical value from the F-distribution to determine if the differences between teaching methods are statistically significant.\n",
        "→ By partitioning the variance, researchers can understand how much of the variability in test scores is due to differences between teaching methods and how much is due to random variation within each method.\n",
        "\n",
        "\n",
        "# Summary :\n",
        "\n",
        "#→ Partitioning of variance in ANOVA is essential for:\n",
        "\n",
        "→ Identifying sources of variability.\n",
        "→ Calculating the F-statistic for hypothesis testing.\n",
        "→ Understanding the contributions of different factors to the total variability.\n",
        "→ Evaluating the significance and effect size of the factors being studied.\n",
        "→ This process allows researchers to make informed decisions based on the data and the relationships between variables.\n"
      ],
      "metadata": {
        "id": "FwVVORAard5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
        "sum of squares (SSR) in a one-way ANOVA using Python?"
      ],
      "metadata": {
        "id": "71QAQFr6qD6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans4.\n",
        "\n",
        "# Here is a detailed explanation and corresponding Python code to perform these calculations.\n",
        "\n",
        "# Calculate SST , SSE and SSR\n",
        "# 1.Total Sum of Square (SST) :\n",
        "# SST =  ∑(X_i - x̄ )^2\n",
        "\n",
        "# Explained Sum of Squares (SSE) :\n",
        "#SSE =  ∑ n_i(x̄_i  - x̄ )^2\n",
        "# n is the number of observation in group i,\n",
        "# x̄_i is the mean of group i.\n",
        "\n",
        "# Residual Sum of Square(SSR) :\n",
        "# SSR =  ∑∑(X_ij - x̄_i )^2\n",
        "\n",
        "# X_ij is each observation in group i.\n",
        "# x̄_i is the mean of group i.\n",
        "\n",
        "\n",
        "## Python Implementation Code :\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Example data :\n",
        "data = {'Group' : ['A','A','A','B','B','B','C','C','C'],\n",
        "        'Value' : [4,5,6,5,6,7,6,7,8]}\n",
        "\n",
        "# Create Dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculation the overall mean\n",
        "overall_mean = df['Value'].mean()\n",
        "\n",
        "# Calculate the group means\n",
        "group_means = df.groupby('Group')['Value'].mean()\n",
        "\n",
        "# Total Sum of Squares (SST)\n",
        "df['SST'] = (df['Value'] - overall_mean) ** 2\n",
        "SST = df['SST'].sum()\n",
        "\n",
        "# Explained Sum of Squares (SSE)\n",
        "df['SSE'] = df['Group'].apply(lambda x : len(df[df['Group']==x]))*(group_means -overall_mean)**2\n",
        "SSE = df.drop_duplicates(subset = 'Group')['SSE'].sum\n",
        "\n",
        "#Residual Sum of Squares (SSR)\n",
        "df = df.merge(group_means, on = 'Group', suffixes = ('','_group_mean'))\n",
        "df['SSR'] = (df['Value']- df['Value_group_mean'])**2\n",
        "SSR = df['SSR'].sum()\n",
        "\n",
        "print(f\"Total Sum of Squares (SST) : {SST}\")\n",
        "print(f\"Explained Sum of Squares (SSE) : {SSE}\")\n",
        "print(f\"Residual Sum of Squares (SSR) : {SSR}\")\n",
        "\n",
        "\n",
        "# Explanation of the Code\n",
        "\n",
        "# 2.Data Preparation:\n",
        "\n",
        "#Create a DataFrame df with the example data.\n",
        "\n",
        "#2.Overall Mean:\n",
        "\n",
        "→ Calculate the overall mean of all observations.\n",
        "\n",
        "#3.Group Means:\n",
        "\n",
        "→ Calculate the mean for each group.\n",
        "\n",
        "# 4.Total Sum of Squares (SST):\n",
        "\n",
        "→ Calculate the squared differences between each observation and the overall mean.\n",
        "→ Sum these squared differences to get SST.\n",
        "\n",
        "# 5.Explained Sum of Squares (SSE):\n",
        "\n",
        "→ Calculate the squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
        "→ Sum these squared differences to get SSE.\n",
        "\n",
        "# 6.Residual Sum of Squares (SSR):\n",
        "\n",
        "→ Calculate the squared differences between each observation and its respective group mean.\n",
        "→ Sum these squared differences to get SSR.\n",
        "\n",
        "# Results :\n",
        "→ When you run the code, it will output the values of SST, SSE, and SSR, which represent the total variability,\n",
        "→  the variability explained by the groups, and the residual variability within the groups, respectively.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwM15D80reeD",
        "outputId": "7cfeabcb-6714-456b-c5af-2bf27e7bd0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sum of Squares (SST) : 12.0\n",
            "Explained Sum of Squares (SSE) : <bound method NDFrame._add_numeric_operations.<locals>.sum of 0   NaN\n",
            "3   NaN\n",
            "6   NaN\n",
            "Name: SSE, dtype: float64>\n",
            "Residual Sum of Squares (SSR) : 6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
      ],
      "metadata": {
        "id": "LAFcqA0OqD2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans5.\n",
        "\n",
        "# To calculate the main effects and interaction effect in a two-way ANOVA using Python , you can use libraries such as 'statsmodels' and 'pandas'.\n",
        "# Here is a detailed explanation and corresponding Python code.\n",
        "\n",
        "# Steps to Calculate Main Effects and Interaction Effets\n",
        "\n",
        "# 1. Main Effects :\n",
        "#The main effects are the effects of each independent variable on the dependent variable, ignoring the other independent varible.\n",
        "#For example if you have two factors, 'A' and 'B' the main effect of 'A' is the effect of 'A' average over all levels of 'B' and vica versa.\n",
        "\n",
        "# Interaction Effects :\n",
        "\n",
        "#The interaction effect is the combination effect of two factors, indicating whether the effect of one factor depends on the level of the other factor.\n",
        "\n",
        "## Python Implementation : How to perform a two-way ANOVA using 'statsmodels' :\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Example data\n",
        "data = {\n",
        "    'Factor_A': ['Low', 'Low', 'Low', 'High', 'High', 'High', 'Low', 'Low', 'Low', 'High', 'High', 'High'],\n",
        "    'Factor_B': ['Low', 'Low', 'High', 'Low', 'Low', 'High', 'High', 'High', 'Low', 'High', 'High', 'Low'],\n",
        "    'Value': [4, 5, 6, 5, 6, 7, 6, 7, 8, 8, 7, 6]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Fit the models\n",
        "model = ols('Value ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B)', data = df).fit()\n",
        "\n",
        "# Perform  ANOVA :\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)\n",
        "\n",
        "\n",
        "## Explanation of the Code :-\n",
        "\n",
        "#1.Data Preparation:\n",
        "\n",
        "→ Create a DataFrame df with the example data, including two factors (Factor_A and Factor_B) and the dependent variable (Value).\n",
        "\n",
        "#2.Fitting the Model:\n",
        "\n",
        "→ Use the ols (Ordinary Least Squares) function from statsmodels.formula.api to define the model. The formula Value ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B) specifies the main effects of Factor_A and Factor_B, and their interaction effect (C(Factor_A):C(Factor_B)).\n",
        "→ The C() function is used to indicate that Factor_A and Factor_B are categorical variables.\n",
        "\n",
        "# 3.Performing ANOVA:\n",
        "\n",
        "→ Use sm.stats.anova_lm to perform the ANOVA on the fitted model. The typ=2 argument specifies the type of sums of squares to use (Type II).\n",
        "\n",
        "# 4.Results:\n",
        "\n",
        "→ The anova_table contains the ANOVA results, including the sum of squares, degrees of freedom, F-statistic, and p-values for the main effects and interaction effect.\n",
        "\n",
        "→ sum_sq: Sum of squares for each source of variation (Factor_A, Factor_B, interaction, and residuals).\n",
        "→ df: Degrees of freedom associated with each source of variation.\n",
        "\n",
        "→ F: F-statistic for each source of variation.\n",
        "→  PR(>F): p-value associated with each F-statistic.\n",
        "→  This table provides the information needed to assess the significance of the main effects and interaction effect.\n",
        "→  If the p-value for a factor or interaction is below a chosen significance level (e.g., 0.05), it indicates a statistically significant effect.\n",
        "\n",
        "# Summary :\n",
        "\n",
        "→ By following these steps and using the provided Python code, you can calculate and interpret the main effects and interaction effects in a two-way ANOVA,\n",
        "→  providing valuable insights into the relationships between the factors and the dependent variable.\n"
      ],
      "metadata": {
        "id": "moshEPNWrfOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6232b95c-2a14-4dc7-d533-f8eabb78a094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            sum_sq   df       F    PR(>F)\n",
            "C(Factor_A)               0.750000  1.0  0.5625  0.474731\n",
            "C(Factor_B)               4.083333  1.0  3.0625  0.118233\n",
            "C(Factor_A):C(Factor_B)   0.750000  1.0  0.5625  0.474731\n",
            "Residual                 10.666667  8.0     NaN       NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
        "What can you conclude about the differences between the groups, and how would you interpret these\n",
        "results?"
      ],
      "metadata": {
        "id": "YhM2ahNuqDyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans6.\n",
        "\n",
        "# When conducting a one-way ANOVA, the goal is to detemine if there are any statistically significant differences between the means of three or more independent (unrelated) groups.\n",
        "#The F-statistic and the p-value obtained from the ANOVA test are used to make this determination.\n",
        "\n",
        "# Given data :\n",
        "→  F-statistic = 5.23\n",
        "→  p-value = 0.02\n",
        "\n",
        "# Hypothesis :\n",
        "# Null Hypothesis (Ho) : All group means are equal. There is no significant difference between the groups.\n",
        "# Alternative Hypothesis (Ha) : At least one group mean is different from the others.\n",
        "\n",
        "# Significance Level (α) :\n",
        "→  Commonly used significance levels are 0.05, 0.01, 0.10. In this case, let's assume α = 0.05\n",
        "\n",
        "#3. Compare p-value to α :\n",
        "# if the p-value is less than α, We Reject th Null Hypothesis.\n",
        "# if the p-value is greater than α, We Fail to Reject the Null Hypothesis.''\n",
        "\n",
        "# Conclusion Based on the Given Results:\n",
        "\n",
        "# F-statistic: 5.23\n",
        "\n",
        "# The F-statistic indicates the ratio of the variance between the group means to the variance within the groups.\n",
        " A higher F-statistic generally indicates a greater degree of variation between the groups relative to the variation within the groups.\n",
        "\n",
        "# p-value: 0.02\n",
        "\n",
        "#The p-value indicates the probability of obtaining an F-statistic at least as extreme as 5.23, assuming the null hypothesis is true.\n",
        "#  A p-value of 0.02 means there is a 2% chance that the observed differences between the group means are due to random variation alone.\n",
        "\n",
        "#Since the p-value (0.02) is less than the significance level (Conclusion Based on the Given Results:\n",
        "\n",
        "→ F-statistic: 5.23\n",
        "\n",
        "#The F-statistic indicates the ratio of the variance between the group means to the variance within the groups.\n",
        "# A higher F-statistic generally indicates a greater degree of variation between the groups relative to the variation within the groups.\n",
        "\n",
        "→ p-value: 0.02\n",
        "\n",
        "→ The p-value indicates the probability of obtaining an F-statistic at least as extreme as 5.23, assuming the null hypothesis is true.\n",
        "→  A p-value of 0.02 means there is a 2% chance that the observed differences between the group means are due to random variation alone.\n",
        "\n",
        "→ Since the p-value (0.02) is less than the significance level (α = 0.05),\n",
        "→ we reject the null hypothesis. This means there is statistically significant evidence to suggest that not all group means are equal.\n",
        "→  In other words, there is a significant difference between the groups.\n",
        "\n",
        "\n",
        "# Interpretation of the Results:\n",
        "\n",
        "# Statistical Significance:\n",
        "\n",
        "→ The test results indicate that there are significant differences between the means of the groups.\n",
        "→  This suggests that the factor being studied has a significant effect on the dependent variable.\n",
        "\n",
        "# Practical Significance:\n",
        "\n",
        "→ While statistical significance indicates that a difference exists, it does not provide information about the magnitude or practical significance of the differences.\n",
        "→  Further analysis, such as post-hoc tests, can help determine which specific groups are significantly different from each other and the size of these differences.\n",
        "\n",
        "# Post-Hoc Tests:\n",
        "\n",
        "# To identify which specific groups differ, you can conduct post-hoc tests (e.g., Tukey's HSD, Bonferroni correction).\n",
        "# These tests control for the Type I error rate and provide pairwise comparisons between group means.\n",
        "\n",
        "\n",
        "## Example of Post-Hoc Test in Python :\n",
        "# Perform a post-hoc test using Tukey's HSD in Python\n",
        "\n",
        "## Python Code :\n",
        "\n",
        "import pandas as pd\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Example data :\n",
        "data = {\n",
        "    'Group' : ['A','A','A','B','B','B','C','C','C'],\n",
        "    'Value' : [4,5,6,5,6,7,6,7,8]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame (data)\n",
        "\n",
        "# Perform Tukey's HSD test\n",
        "tukey = pairwise_tukeyhsd (endog=df['Value'], groups= df['Group'],alpha = 0.05)\n",
        "\n",
        "print(tukey)\n",
        "\n",
        "# Conclusion:\n",
        "\n",
        "→ The one-way ANOVA indicates significant differences between the groups, as evidenced by the F-statistic of 5.23 and a p-value of 0.02.\n",
        "→ We reject the null hypothesis that all group means are equal.\n",
        "→ Post-hoc tests should be conducted to determine which specific groups have significant differences in their means and to understand the practical significance of these differences.\n"
      ],
      "metadata": {
        "id": "uXe1VvtTrgCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dfedc10-2542-4fdc-9afb-b0e869d765d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
            "===================================================\n",
            "group1 group2 meandiff p-adj   lower  upper  reject\n",
            "---------------------------------------------------\n",
            "     A      B      1.0 0.4827 -1.5052 3.5052  False\n",
            "     A      C      2.0 0.1089 -0.5052 4.5052  False\n",
            "     B      C      1.0 0.4827 -1.5052 3.5052  False\n",
            "---------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
        "consequences of using different methods to handle missing data?"
      ],
      "metadata": {
        "id": "nQIKCqI0qdgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans7.\n",
        "\n",
        "# Handling missing data in a repeated measures ANOVA is crucial because missing data can bias the results and reduce the power of the analysis.\n",
        "# Several methods can be used to address missing data, each with its advantages and potential consequences.\n",
        "\n",
        "#Methods for Handling Missing Data:\n",
        "\n",
        "#1.Listwise Deletion (Complete Case Analysis)\n",
        "#2.Pairwise Deletion\n",
        "#3.Mean Substitution\n",
        "#4.Last Observation Carried Forward (LOCF)\n",
        "#5.Multiple Imputation\n",
        "#6.Mixed-Effects Models\n",
        "\n",
        "# 1. Listwise Deletion (Complete Case Analysis)\n",
        "\n",
        "# Description:\n",
        "\n",
        "# Exclude any participant who has any missing data.\n",
        "\n",
        "# Consequences:\n",
        "\n",
        "# Advantages: Simple to implement and ensures that all analyses are performed on the same data set.\n",
        "# Disadvantages: Can lead to a significant loss of data, reducing statistical power and potentially introducing bias if the missing data are not completely random.\n",
        "\n",
        "# 2. Pairwise Deletion\n",
        "\n",
        "# Description:\n",
        "\n",
        "#Use all available data for each analysis, excluding only the missing values.\n",
        "#Consequences:\n",
        "\n",
        "#Advantages: Retains more data compared to listwise deletion.\n",
        "#Disadvantages: Can lead to inconsistencies in the sample size across different analyses and may complicate interpretation.\n",
        "\n",
        "# 3. Mean Substitution\n",
        "# Description:\n",
        "\n",
        "# Replace missing values with the mean of the observed values for that variable.\n",
        "#Consequences:\n",
        "\n",
        "# Advantages: Simple and retains all cases.\n",
        "# Disadvantages: Underestimates the variability and can bias the results by reducing the variability in the data.\n",
        "\n",
        "# 4. Last Observation Carried Forward (LOCF)\n",
        "# Description:\n",
        "\n",
        "# Replace missing values with the last observed value for that participant.\n",
        "# Consequences:\n",
        "\n",
        "# Advantages: Retains all participants in the analysis.\n",
        "# Disadvantages: Can introduce bias if the last observation is not representative of the missing values.\n",
        "\n",
        "# 5. Multiple Imputation\n",
        "# Description:\n",
        "\n",
        "# Replace missing values with a set of plausible values based on the observed data, and perform the analysis on each completed data set, combining the results.\n",
        "# Consequences:\n",
        "\n",
        "# Advantages: Accounts for the uncertainty about the missing data and provides more accurate estimates and standard errors.\n",
        "# Disadvantages: Computationally intensive and requires assumptions about the missing data mechanism.\n",
        "\n",
        "# 6. Mixed-Effects Models\n",
        "# Description:\n",
        "\n",
        "# Use all available data by modeling the data with random effects to account for the within-subject correlation.\n",
        "# Consequences:\n",
        "\n",
        "# Advantages: Handles unbalanced data and missing values without requiring imputation, providing unbiased estimates if the missing data mechanism is random.\n",
        "# Disadvantages: More complex to implement and interpret compared to traditional ANOVA.\n",
        "\n",
        "\n",
        "## Implementing Mixed-Effects , Models in Python :-\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import mixedlm\n",
        "\n",
        "#Example data\n",
        "data = {'Subject' : [1,1,1,2,2,2,3,3,3],\n",
        "        'Time' : ['T1','T2','T3','T1','T2','T3','T1','T2','T3'],\n",
        "        'Score' : [5,6,None, 7,8,9,4, None,5]\n",
        "\n",
        "}\n",
        "\n",
        "#Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#Fit the mixed-effects model\n",
        "model = mixedlm(\"Score ~ Time\", df, groups=df[\"Subject\"])\n",
        "result = model.fit()\n",
        "\n",
        "print(result.summary())\n",
        "\n",
        "\n",
        "# Consequences of Using Different Methods :\n",
        "\n",
        "# →  Listwise Deletion:\n",
        "# →  Loss of data leads to reduced power and potential bias.\n",
        "\n",
        "# Pairwise Deletion:\n",
        "# → Inconsistency in sample sizes can lead to problems in interpretation.\n",
        "\n",
        "# Mean Substitution:\n",
        "# →  Reduces variability and can bias results, leading to inaccurate estimates of the effects.\n",
        "\n",
        "# LOCF:\n",
        "# → Can introduce bias if the last observation is not a good estimate of the missing data.\n",
        "\n",
        "# Multiple Imputation:\n",
        "# →  Provides more accurate estimates but is computationally intensive and requires assumptions about the missing data mechanism.\n",
        "\n",
        "# Mixed-Effects Models:\n",
        "#→ Handles missing data well, unbiased if data are MAR. but more complex to implement and interpret.else\n",
        "\n",
        "# Conclusion :\n",
        "\n",
        "# → Choosing the appropriate method to handle missing data in a repeated measures ANOVA is crucial for maintaining the integrity of your analysis.\n",
        "# →  By carefully assessing the extent and pattern of missing data and selecting the most suitable method\n"
      ],
      "metadata": {
        "id": "a9J2oQgCrh8z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "9df57f6e-fe43-4917-d7f3-317f2e7c9855"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 7 is out of bounds for axis 0 with size 7",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d8bd2dd95881>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m#Fit the mixed-effects model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixedlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score ~ Time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Subject\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, formula, data, re_formula, vc_formula, subset, use_sparse, missing, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exog_vc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog_vc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"groups\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;31m# expand re names to account for pairs of RE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0;34m'formula'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# attach formula for unpckling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                        'design_info': design_info})\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# since we got a dataframe, attach the original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, groups, exog_re, exog_vc, use_sqrt, missing, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;31m# Split the data by groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog_li\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog_li\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog_re_li\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog_re\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mgroup_list\u001b[0;34m(self, array)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             return [np.array(array[self.row_indices[k]])\n\u001b[0m\u001b[1;32m   1104\u001b[0m                     for k in self.group_labels]\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             return [np.array(array[self.row_indices[k]])\n\u001b[0m\u001b[1;32m   1104\u001b[0m                     for k in self.group_labels]\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 7"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
        "an example of a situation where a post-hoc test might be necessary."
      ],
      "metadata": {
        "id": "XoDzZFfvqdbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans8.\n",
        "\n",
        "# After performing an ANOVA and finding a significant result, indicating that there are differences between group means, it is often necessary to determine which specific groups are different from each other. This is where post-hoc tests come into play. Here are some common post-hoc tests and when to use each one, along with an example scenario.\n",
        "\n",
        "# Common Post-Hoc Tests :\n",
        "\n",
        "#1. Tukey's Honestly Significant Difference (HSD) Test\n",
        "#2. Bonferroni Correction\n",
        "# 3.Scheffé's Test\n",
        "# 4.Dunnett's Test\n",
        "# 5.Fisher's Least Significant Difference (LSD) Test\n",
        "# 6.Holm-Bonferroni Method\n",
        "\n",
        "# 1. Tukey's Honestly Significant Difference (HSD) Test\n",
        "# Use:\n",
        "\n",
        "#→  Best for pairwise comparisons when you want to control the family-wise error rate.\n",
        "#→ Appropriate when you have equal sample sizes in each group, but can also be used with unequal sample sizes.\n",
        "\n",
        "# Example:\n",
        "#→ Comparing the average test scores of students from four different teaching methods to identify which methods differ from each other.\n",
        "\n",
        "# 2. Bonferroni Correction\n",
        "# Use:\n",
        "\n",
        "#→ Controls the family-wise error rate by adjusting the significance level for each individual test.\n",
        "#→ Suitable for a small number of comparisons due to its conservative nature.\n",
        "\n",
        "# 3. Scheffé's Test\n",
        "# Use:\n",
        "\n",
        "#→ More flexible than Tukey’s HSD as it can be used for both pairwise and complex comparisons.\n",
        "#→ Suitable for unplanned comparisons.\n",
        "\n",
        "#Example:\n",
        "#→ Comparing multiple treatment effects in a clinical trial where some treatments might be combined into one group.\n",
        "\n",
        "# 4. Dunnett's Test\n",
        "# Use:\n",
        "\n",
        "#→ Compare each treatment group to a single control group.\n",
        "#→ Suitable when you have a control group and several treatment groups.\n",
        "\n",
        "# Example:\n",
        "#→ Testing the effectiveness of new drugs compared to a placebo.\n",
        "\n",
        "# 5. Fisher's Least Significant Difference (LSD) Test\n",
        "# Use:\n",
        "\n",
        "#→ Simple pairwise comparisons without adjusting for multiple comparisons.\n",
        "#→ Suitable for exploratory analysis, but not recommended due to high Type I error rate.\n",
        "\n",
        "# Example:\n",
        "#→ Initial comparison of different fertilizers on plant growth.\n",
        "\n",
        "# 6. Holm-Bonferroni Method\n",
        "# Use:\n",
        "\n",
        "#→ Adjusts p-values to control the family-wise error rate while maintaining more power than the Bonferroni correction.\n",
        "#→ Suitable for multiple comparisons with a higher likelihood of detecting significant differences.\n",
        "\n",
        "\n",
        "# Example Scenario\n",
        "# Situation:\n",
        "\n",
        "#→ A researcher wants to compare the effectiveness of four different study techniques on students' test scores.\n",
        "\n",
        "# Step:\n",
        "#→ Conduct a one-way ANOVA to determine if there are any overall differences between the techniques.\n",
        "#→ If the ANOVA is significant, use Tukey's HSD test to identify which specific techniques differ from each other.\n",
        "\n",
        "# Conclusion :\n",
        "\n",
        "#→ Post-hoc tests are crucial for understanding specific group differences after finding a significant ANOVA result.\n",
        "#→  Each test has its strengths and weaknesses, and the choice of test depends on the specific context and research questions.\n",
        "\n",
        "\n",
        "# Compare the average test scores of students from four different teaching methods to identify which methods differ from each other\n",
        "## Use  Python Code\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Example data\n",
        "data = {\n",
        "    'Method': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D'],\n",
        "    'Score': [82, 85, 88, 78, 80, 84, 90, 92, 94, 76, 78, 79]\n",
        "}\n",
        "\n",
        "df =pd.DataFrame(data)\n",
        "\n",
        "# Perform Tukey's HSD test\n",
        "tukey = pairwise_tukeyhsd(endog=df['Score'], groups=df['Method'], alpha=0.05)\n",
        "print(tukey)\n",
        "\n",
        "\n",
        "## Scheff's Test : Python Code\n",
        "# Comparing multiple teatment effects in a clinical trial where some treatments might be combined into one group.\n",
        "\n",
        "\n",
        "\n",
        "from statsmodels.stats.libqsturng import psturng\n",
        "\n",
        "# Example F-statistic and degrees of freedom\n",
        "f_statistic = 4.35\n",
        "df_between = 3\n",
        "df_within = 24\n",
        "\n",
        "# Scheffé's critical value\n",
        "critical_value = psturng(f_statistic, df_between, df_within)\n",
        "print(critical_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg4kZF4ZvLmX",
        "outputId": "d8591330-e5f2-4f4b-8046-392aeaf7fd1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
            "=====================================================\n",
            "group1 group2 meandiff p-adj   lower    upper  reject\n",
            "-----------------------------------------------------\n",
            "     A      B  -4.3333 0.2206 -10.8264  2.1597  False\n",
            "     A      C      7.0 0.0352    0.507  13.493   True\n",
            "     A      D  -7.3333 0.0281 -13.8264 -0.8403   True\n",
            "     B      C  11.3333 0.0023   4.8403 17.8264   True\n",
            "     B      D     -3.0 0.4906   -9.493   3.493  False\n",
            "     C      D -14.3333 0.0005 -20.8264 -7.8403   True\n",
            "-----------------------------------------------------\n",
            "[0.01380227]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
        "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
        "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
        "Report the F-statistic and p-value, and interpret the results."
      ],
      "metadata": {
        "id": "jNZ8KL_mqdW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans9.\n",
        "\n",
        "# Sure, let's perform a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of three diets.\n",
        "# Here are the steps to conduct this analysis:\n",
        "\n",
        "# 1.Generate or load the data.\n",
        "# 2.Conduct the one-way ANOVA.\n",
        "# 3.Report the F-statistic and p-value.\n",
        "# 4.Interpret the results.\n",
        "\n",
        "\n",
        "# Step 1: Generate or Load the Data :\n",
        "\n",
        "# Assume we have the weight loss data for 50 participants assigned to one of the three diets (A, B, or C). Here’s an example dataset:\n",
        "\n",
        "# Python Code :\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulated weight loss data for 50 participants\n",
        "data = {\n",
        "    'Diet': np.random.choice(['A', 'B', 'C'], 50),\n",
        "    'WeightLoss': np.random.normal(loc=[5, 7, 6], scale=2, size=50)  # mean weight loss around 5, 7, 6 kg respectively\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.loc[df['Diet'] == 'A', 'WeightLoss'] += np.random.normal(0, 1, df[df['Diet'] == 'A'].shape[0])\n",
        "df.loc[df['Diet'] == 'B', 'WeightLoss'] += np.random.normal(0, 1, df[df['Diet'] == 'B'].shape[0])\n",
        "df.loc[df['Diet'] == 'C', 'WeightLoss'] += np.random.normal(0, 1, df[df['Diet'] == 'C'].shape[0])\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Step 2: Conduct the One-way ANOVA -\n",
        "\n",
        "# Use the 'statsmodels' library to perform the one-way ANOVA.\n",
        "## Python Code :\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Perform the ANOVA\n",
        "model = ols('WeightLoss ~ Diet', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Display the ANOVA table\n",
        "print(anova_table)\n",
        "\n",
        "\n",
        "## Report F-statistic and p-value, Use Python Code :\n",
        "\n",
        "f_statistic = anova_table['F'][0]\n",
        "p_value = anova_table['PR(>F)'][0]\n",
        "print(f\"F-statistic: {f_statistic:.2f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation of results\n",
        "if p_value < 0.05:\n",
        "    print(\"There is a significant difference in mean weight loss between the diets.\")\n",
        "else:\n",
        "    print(\"There is no significant difference in mean weight loss between the diets.\")\n",
        "\n",
        "\n",
        "# Step 3: Report the F-Statistic and P-Value :\n",
        "\n",
        "→ The output of the ANOVA table will include the F-statistic and p-value.\n",
        "\n",
        "# Step 4: Interpret the Results :\n",
        "→ Interpret the F-statistic and p-value to determine if there are significant differences between the diets.\n",
        "\n",
        "\n",
        "# Interpretation :\n",
        "\n",
        "→ If the p-value is less than 0.05, it suggests that there are significant differences in mean weight loss between at least two of the diets.\n",
        "→ The F-statistic provides a measure of the ratio of the variance between the group means to the variance within the groups. A higher F-statistic generally indicates that there is more variability between the groups compared to within the groups, supporting the conclusion of significant differences.\n"
      ],
      "metadata": {
        "id": "5CUriqM5zBVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
        "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
        "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
        "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
        "interaction effects between the software programs and employee experience level (novice vs.\n",
        "experienced). Report the F-statistics and p-values, and interpret the results."
      ],
      "metadata": {
        "id": "d6ejim1kqdR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans10.\n",
        "\n",
        "# To conduct a two-way ANOVA using Python, we need to consider two factors: the software program (Program A, Program B, Program C) and the employee experience level (novice vs. experienced). We will generate a dataset, perform the ANOVA, and interpret the results.\n",
        "\n",
        "# Step-by-Step Approach :\n",
        "\n",
        "#1.Generate the data.\n",
        "#2.Conduct the two-way ANOVA.\n",
        "#3.Report the F-statistics and p-values.\n",
        "#4.Interpret the results.\n",
        "\n",
        "# Step 1: Generate the Data :\n",
        "# Let's create a synthetic dataset of 30 employees, with each assigned to one of the programs and labeled as either novice or experienced.\n",
        "\n",
        "# Python Code :\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data\n",
        "n = 30\n",
        "data = {\n",
        "    'Employee': np.arange(n),\n",
        "    'Program': np.random.choice(['A', 'B', 'C'], n),\n",
        "    'Experience': np.random.choice(['Novice', 'Experienced'], n),\n",
        "    'Time': np.random.normal(loc=0, scale=1, size=n)  # to be adjusted based on groups\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Adjust mean task completion time based on program and experience\n",
        "df.loc[(df['Program'] == 'A') & (df['Experience'] == 'Novice'), 'Time'] += np.random.normal(25, 5, df[(df['Program'] == 'A') & (df['Experience'] == 'Novice')].shape[0])\n",
        "df.loc[(df['Program'] == 'A') & (df['Experience'] == 'Experienced'), 'Time'] += np.random.normal(20, 5, df[(df['Program'] == 'A') & (df['Experience'] == 'Experienced')].shape[0])\n",
        "df.loc[(df['Program'] == 'B') & (df['Experience'] == 'Novice'), 'Time'] += np.random.normal(30, 5, df[(df['Program'] == 'B') & (df['Experience'] == 'Novice')].shape[0])\n",
        "df.loc[(df['Program'] == 'B') & (df['Experience'] == 'Experienced'), 'Time'] += np.random.normal(25, 5, df[(df['Program'] == 'B') & (df['Experience'] == 'Experienced')].shape[0])\n",
        "df.loc[(df['Program'] == 'C') & (df['Experience'] == 'Novice'), 'Time'] += np.random.normal(28, 5, df[(df['Program'] == 'C') & (df['Experience'] == 'Novice')].shape[0])\n",
        "df.loc[(df['Program'] == 'C') & (df['Experience'] == 'Experienced'), 'Time'] += np.random.normal(22, 5, df[(df['Program'] == 'C') & (df['Experience'] == 'Experienced')].shape[0])\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Conduct the Two-Way ANOVA :-\n",
        "# We will use the statsmodels library to perform the two-way ANOVA.\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Perform the two-way ANOVA\n",
        "model = ols('Time ~ Program * Experience', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Display the ANOVA table\n",
        "print(anova_table)\n",
        "\n",
        "\n",
        "# Report F-statistics and p-values\n",
        "\n",
        "f_statistic_program = anova_table['F'][0]\n",
        "p_value_program = anova_table['PR(>F)'][0]\n",
        "\n",
        "f_statistic_experience = anova_table['F'][1]\n",
        "p_value_experience = anova_table['PR(>F)'][1]\n",
        "\n",
        "f_statistic_interaction = anova_table['F'][2]\n",
        "p_value_interaction = anova_table['PR(>F)'][2]\n",
        "\n",
        "print(f\"F-statistic for Program: {f_statistic_program:.2f}, p-value: {p_value_program:.4f}\")\n",
        "print(f\"F-statistic for Experience: {f_statistic_experience:.2f}, p-value: {p_value_experience:.4f}\")\n",
        "print(f\"F-statistic for Interaction: {f_statistic_interaction:.2f}, p-value: {p_value_interaction:.4f}\")\n",
        "\n",
        "# Interpretation of results\n",
        "if p_value_program < 0.05:\n",
        "    print(\"There is a significant main effect of the Program on task completion time.\")\n",
        "else:\n",
        "    print(\"There is no significant main effect of the Program on task completion time.\")\n",
        "\n",
        "if p_value_experience < 0.05:\n",
        "    print(\"There is a significant main effect of Experience on task completion time.\")\n",
        "else:\n",
        "    print(\"There is no significant main effect of Experience on task completion time.\")\n",
        "\n",
        "if p_value_interaction < 0.05:\n",
        "    print(\"There is a significant interaction effect between Program and Experience on task completion time.\")\n",
        "else:\n",
        "    print(\"There is no significant interaction effect between Program and Experience on task completion time.\")\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Report the F-Statistics and P-Values :\n",
        "→ The output of the ANOVA table will include the F-statistics and p-values for the main effects (Program and Experience) and their interaction.\n",
        "\n",
        "# Step 4: Interpret the Results :\n",
        "→ We interpret the F-statistics and p-values to determine if there are significant main effects or interaction effects.\n",
        "\n",
        "\n",
        "# Interpretation :\n",
        "\n",
        "→ Main Effect of Program: If the p-value for the Program is less than 0.05, it indicates that there is a significant difference in the average task completion time among the different software programs.\n",
        "→ Main Effect of Experience: If the p-value for Experience is less than 0.05, it suggests that the average task completion time differs significantly between novice and experienced employees.\n",
        "→ Interaction Effect: If the p-value for the interaction between Program and Experience is less than 0.05, it means that the effect of the software program on task completion time depends on the experience level of the employees.\n",
        "→ This analysis helps the company understand not only if there are differences between the software programs and experience levels but also if the impact of the software programs varies depending on the experience level of the employees.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-oOO52X5wCh",
        "outputId": "6419968d-9f38-4fd6-d09b-8e53d74d6c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Employee Program   Experience       Time\n",
            "0         0       C  Experienced  21.858165\n",
            "1         1       A  Experienced  23.770935\n",
            "2         2       C  Experienced  11.460449\n",
            "3         3       C  Experienced  22.753919\n",
            "4         4       A  Experienced  26.767703\n",
            "                        sum_sq    df         F    PR(>F)\n",
            "Program             125.055930   2.0  2.314721  0.120443\n",
            "Experience           77.086828   1.0  2.853675  0.104117\n",
            "Program:Experience   71.278863   2.0  1.319335  0.286012\n",
            "Residual            648.316159  24.0       NaN       NaN\n",
            "F-statistic for Program: 2.31, p-value: 0.1204\n",
            "F-statistic for Experience: 2.85, p-value: 0.1041\n",
            "F-statistic for Interaction: 1.32, p-value: 0.2860\n",
            "There is no significant main effect of the Program on task completion time.\n",
            "There is no significant main effect of Experience on task completion time.\n",
            "There is no significant interaction effect between Program and Experience on task completion time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
        "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
        "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
        "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
        "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
        "group(s) differ significantly from each other."
      ],
      "metadata": {
        "id": "dBNgDWzbqdOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans11.\n",
        "\n",
        "# To conduct a two-sample t-test in Python to determine if there are any significant differences in test scores between the control group (traditional teaching method) and\n",
        "# the experimental group (new teaching method), follow these steps:\n",
        "\n",
        "# 1.Generate or load the data.\n",
        "# 2.Conduct the two-sample t-test.\n",
        "# 3.Report the t-statistic and p-value.\n",
        "# 4.Interpret the results.\n",
        "# 5.If significant, follow up with a post-hoc test.\n",
        "\n",
        "\n",
        "# Step 1: Generate or Load the Data\n",
        "# Let's assume we have test scores for 100 students, with 50 students in each group.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data\n",
        "n = 100\n",
        "data = {\n",
        "    'Group' : np.random.choice (['Control', 'Experimental'],n),\n",
        "    'TestScore' : np.concatenate ([\n",
        "        np.random.normal(75, 10, n//2), # Control group scores\n",
        "        np.random.normal(80, 10, n//2)  # Experimental group scores\n",
        "     ])\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the first rows of the data\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Step2 : Conduct the Two-Sample T-Test\n",
        "# We will use the  'scipy.stats' library to perform the t-test\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "# Separate the data into two groups\n",
        "control_group = df[df['Group']== 'Control']['TestScore']\n",
        "experimental_group = df[df['Group'] == 'Experimental']['TestScore']\n",
        "\n",
        "# Perform the Two-sample t-test\n",
        "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
        "\n",
        "# Display the results\n",
        "print(f\"T-statistic : {t_statistic:.2f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "\n",
        "# Interpretation of results\n",
        "if p_value < 0.05:\n",
        "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
        "else:\n",
        "    print(\"There is no significant difference in test scores between the control and experimental groups.\")\n",
        "\n",
        "\n",
        "# Interpretation :\n",
        "\n",
        "→ T-Statistic: The t-statistic measures the size of the difference relative to the variation in your sample data.\n",
        "→ P-Value: The p-value tells you the probability that the results from your sample data occurred by chance. A p-value less than 0.05 is typically considered statistically significant.\n",
        "→ If the p-value is less than 0.05, you can conclude that there is a significant difference in test scores between the control and experimental groups,\n",
        "→ suggesting that the new teaching method has a different effect compared to the traditional method.\n",
        "\n"
      ],
      "metadata": {
        "id": "hOsZA_mGrkl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13af7ac5-68bc-4e8f-a462-0473e785070d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Group  TestScore\n",
            "0       Control  82.384666\n",
            "1  Experimental  76.713683\n",
            "2       Control  73.843517\n",
            "3       Control  71.988963\n",
            "4       Control  60.214780\n",
            "T-statistic : 0.72\n",
            "p-value: 0.4739\n",
            "There is no significant difference in test scores between the control and experimental groups.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
        "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
        "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
        "\n",
        "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
        "hoc test to determine which store(s) differ significantly from each other."
      ],
      "metadata": {
        "id": "N5IyRBr2q6x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans12.\n",
        "\n",
        "# To conduct a repeated measures ANOVA using Python, we need to consider that the same days are used to record sales for all three stores.\n",
        "# This implies that the sales data are dependent, making repeated measures ANOVA appropriate.\n",
        "\n",
        "# Step-by-Step Approach :\n",
        "\n",
        "#1.Generate or load the data.\n",
        "#2.Conduct the repeated measures ANOVA.\n",
        "#3.Report the results.\n",
        "#4If significant, follow up with a post-hoc test.\n",
        "\n",
        "\n",
        "# Step 1: Generate or Load the Data:\n",
        "# Let's create a synthetic dataset of sales for 30 days for three stores (Store A, Store B, Store C).\n",
        "\n",
        "\n",
        "# Python Code :\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data\n",
        "days = 30\n",
        "sales_data = {\n",
        "    'Day' : np.arange(1, days + 1),\n",
        "    'StoreA' : np.random.normal(200,20, days),\n",
        "    'StoreB' : np.random.normal(220,20, days),\n",
        "    'StoreC' : np.random.normal(220, 20, days)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(sales_data)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Conduct the Repeated Measures ANOVA\n",
        "# We will use the 'statsmodels' library to perform the repeated measures ANOVA.\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import AnovaRM\n",
        "\n",
        "# Melt the dataframe to long format\n",
        "df_long = pd.melt(df, id_vars= ['Day'], value_vars= ['StoreA', 'StoreB', 'StoreC'],\n",
        "                  var_name = 'Store', value_name = 'Sales')\n",
        "\n",
        "# Display the first few rows of the long format data\n",
        "print (df_long.head())\n",
        "\n",
        "# Perform the repeated measures ANOVA\n",
        "aovrm = AnovaRM (df_long, 'Sales', 'Day', within= ['Store'])\n",
        "res = aovrm.fit()\n",
        "\n",
        "# Display the results\n",
        "print(res)\n",
        "\n",
        "\n",
        "#  Report the Results :\n",
        "# The output will include the F-statistic and p-value for the main effect of the store.\n",
        "\n",
        "# Post-Hoc Test :\n",
        "# If the ANOVA results are significant, we can perform pairwise comparisons using a post-hoc test like Tukey's HSD.\n",
        "# Since Tukey's HSD is not directly available for repeated measures in statsmodels, we can use the pairwise_tukeyhsd function from statsmodels.stats.multicomp.\n",
        "\n",
        "# Here the complete code to conduct the repeated meansures ANOVA and post-hoc test if necessary.\n",
        "\n",
        "# Interpretation of results Used Python Code :\n",
        "if res.anova_table['Pr > F'][0] < 0.05 :\n",
        "  print (\"There is a significant difference in sales between the stores.\")\n",
        "\n",
        "else :\n",
        "  print (\"There is no significant difference in sales between the stores.\")\n",
        "\n",
        "# Post-hoc test if significant\n",
        "if res.anova_table['Pr > F'][0] < 0.05 :\n",
        "  posthoc = pairwise_tukeyhsd(df_long ['Sales'], df_long['Store'])\n",
        "  print(posthoc)\n",
        "\n",
        "\n",
        "# Interpretation :\n",
        "\n",
        "→ ANOVA Results : The F-statistic and p-value will tell us if there are significant differences in sales between the threee stores.\n",
        "→ Post-Hoc Test : if the ANOVA results are significant, the post-hoc test will indicate which stores differ significantly form each other.\n",
        "\n",
        "→ AnovaRM : The 'AnovaRM' function is used to perform the repeated measures ANOVA.\n",
        "# 'pairwise_tukeyhsd' : It is used for the post -hoc analysis. The output will provide a clear understanding of whethe there are significant differences in sales between the stores and pairs of stores differ signifcantly.\n"
      ],
      "metadata": {
        "id": "8pCHhOo_p75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "659a7492-01ff-45f5-fd80-437613830a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Day      StoreA      StoreB      StoreC\n",
            "0    1  209.934283  207.965868  210.416515\n",
            "1    2  197.234714  257.045564  216.286820\n",
            "2    3  212.953771  219.730056  197.873301\n",
            "3    4  230.460597  198.845781  196.075868\n",
            "4    5  195.316933  236.450898  236.250516\n",
            "   Day   Store       Sales\n",
            "0    1  StoreA  209.934283\n",
            "1    2  StoreA  197.234714\n",
            "2    3  StoreA  212.953771\n",
            "3    4  StoreA  230.460597\n",
            "4    5  StoreA  195.316933\n",
            "               Anova\n",
            "===================================\n",
            "      F Value Num DF  Den DF Pr > F\n",
            "-----------------------------------\n",
            "Store 15.2367 2.0000 58.0000 0.0000\n",
            "===================================\n",
            "\n",
            "There is a significant difference in sales between the stores.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pairwise_tukeyhsd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f75bd4507d1f>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Post-hoc test if significant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manova_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pr > F'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m   \u001b[0mposthoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_tukeyhsd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_long\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposthoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pairwise_tukeyhsd' is not defined"
          ]
        }
      ]
    }
  ]
}